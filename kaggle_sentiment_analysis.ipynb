{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kaggle_sentiment_analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPxfunLcifUwbitmzU6irsq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asanoop24/dl-nlp/blob/master/kaggle_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ubfA6NheKIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb6JFO9zfcdS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m6-KdtWyH4z",
        "colab_type": "code",
        "outputId": "a4691f14-c977-4ce2-b1aa-742a7ca6bf48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!unzip /content/kaggle_sentiment_analysis/train.tsv.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/kaggle_sentiment_analysis/train.tsv.zip\n",
            "  inflating: train.tsv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWufAQ-vyTf0",
        "colab_type": "code",
        "outputId": "8ec6a610-bc1d-4f2a-8b3f-c085ad65e482",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!unzip /content/kaggle_sentiment_analysis/test.tsv.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/kaggle_sentiment_analysis/test.tsv.zip\n",
            "  inflating: test.tsv                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDxp8LcfhqXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pandas.read_table('/content/kaggle_sentiment_analysis/train.tsv')\n",
        "test_df = pandas.read_table('/content/kaggle_sentiment_analysis/test.tsv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmSrVwmItuWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df[:30]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhdXc0d4yzaH",
        "colab_type": "code",
        "outputId": "f38a722d-29c4-43cd-a857-2bb92db629e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import string\n",
        "string.punctuation"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRP_uKdwi41a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_text = ' '.join([r['Phrase'] for i,r in train_df.iterrows()])\n",
        "all_text = ''.join([c for c in all_text if c not in string.punctuation])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLO5XcG-zu6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "words = [w.lower() for w in all_text.split()]\n",
        "count_words = Counter(words)\n",
        "total_words = len(words)\n",
        "sorted_words = count_words.most_common(total_words)\n",
        "vocab_words = {w:i for i,(w,c) in enumerate(sorted_words)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df3RvC8ch41e",
        "colab_type": "code",
        "outputId": "45afdcbd-f0c5-4617-a7e1-cca986805ae2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab_targets = {s:i for i,s in enumerate(sorted(train_df['Sentiment'].value_counts().index))}\n",
        "vocab_targets"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTzFjuc6D_mj",
        "colab_type": "code",
        "outputId": "f9805cb6-32e7-40a9-9363-7659fdf1fb5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab_words['and']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KO8Jnbx2TIK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sequence_to_tensor(sequence, vocab, dtype=torch.long):\n",
        "    idxs = [vocab[word] if word in vocab else len(vocab)+1 for word in sequence]\n",
        "    return torch.tensor(idxs, dtype=dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq-YRol_X08u",
        "colab_type": "code",
        "outputId": "fe306081-7680-42fd-e942-6e91798179c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "#.keys()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLfRur5PCEux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_seq = [sequence_to_tensor(''.join([c.lower() for c in sentence if c not in string.punctuation]).split(), vocab_words) for sentence in train_df['Phrase'].tolist()]\n",
        "test_seq = [sequence_to_tensor(''.join([c.lower() for c in sentence if c not in string.punctuation]).split(), vocab_words) for sentence in test_df['Phrase'].tolist()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTrPkuKoGHn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def pad_features(inputs, seq_length):\n",
        "    ''' Return features of review_ints, where each review is padded with 0's or truncated to the input seq_length.\n",
        "    '''\n",
        "    features = np.zeros((len(inputs), 48), dtype = int)\n",
        "    \n",
        "    for i, review in enumerate(inputs):\n",
        "        review_len = len(review)\n",
        "        \n",
        "        if review_len <= seq_length:\n",
        "            zeroes = list(np.zeros(seq_length-review_len))\n",
        "            new = zeroes+review\n",
        "        elif review_len > seq_length:\n",
        "            new = review[0:seq_length]\n",
        "        \n",
        "        features[i,:] = np.array(new)\n",
        "    \n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwhX2qHMFDyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_seq_padded = pad_features([i.tolist() for i in train_seq], 48)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKh-apXsZJsI",
        "colab_type": "code",
        "outputId": "1fa3602a-e044-4a05-9534-557c7077dad3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "train_seq_padded[:4]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     1,   303,     2, 15109,  5905,\n",
              "            0,  6498,     8,    50,     7,    48,    12,     0,  3513,\n",
              "            7,   166,    48,    12,     0, 11380,    61,     2,    74,\n",
              "          614, 10452,    18,   575,     2,    74,  2002,     4,    53,\n",
              "            2,     1,    39],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     1,   303,\n",
              "            2, 15109,  5905,     0,  6498,     8,    50,     7,    48,\n",
              "           12,     0,  3513],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     1,   303],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XppcGoXiMfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentimentLSTM(nn.Module):\n",
        "  def __init__(embedding_dim, hidden, vocab_dim, target_dim, num_layers, dropout):\n",
        "    super(SentimentLSTM, self).__init__()\n",
        "    self.embedding = nn.Embedding(vocab_dim, embedding_dim)\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, dropout)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.fc = nn.Linear(hidden_dim, target_dim)\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "  def forward(self, sequence):\n",
        "    embedding = self.embedding(sequence)\n",
        "    out, hidden = self.lstm(embedding, hidden)\n",
        "    out = self.dropout(out)\n",
        "    out = self.fc(out)\n",
        "    out = self.softmax(out)\n",
        "    return out, hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3I9PGkSvm-f",
        "colab_type": "code",
        "outputId": "d3738f99-dddb-4497-8067-f468f0915c16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.device('cuda')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    }
  ]
}